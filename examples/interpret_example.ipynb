{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from wittgenstein.irep import IREP\n",
    "from wittgenstein.ripper import RIPPER\n",
    "from wittgenstein.interpret import interpret_model, score_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpath = ''\n",
    "df = pd.read_csv(inpath+\"wine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split\n",
    "\n",
    "X, y = df.drop('Class', axis=1), df['Class']\n",
    "y = y.map(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interpreter\n",
    "\n",
    "interpreter = RIPPER(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Proline=>1227.0] V\n",
      "[Proline=1048.0-1227.0] V\n",
      "[Proline=880.0-1048.0]]\n"
     ]
    }
   ],
   "source": [
    "# Interpret an SVM\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=42)\n",
    "svc.fit(X_train, y_train);\n",
    "\n",
    "interpret_model(model=svc, X=X_train, interpreter=interpreter)\n",
    "interpreter.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_fidelity(\n",
    "    X_test,\n",
    "    interpreter,\n",
    "    model=svc,\n",
    "    score_function=[precision_score, recall_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Proline=>1227.0] V\n",
      "[Proline=1048.0-1227.0] V\n",
      "[Proline=880.0-1048.0 ^ Ash=2.0-2.19] V\n",
      "[Proline=880.0-1048.0 ^ Malicacid=1.76-1.9] V\n",
      "[Colorintensity=5.75-6.78]]\n"
     ]
    }
   ],
   "source": [
    "# Interpret a Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "ruleset, _ = interpret_model(model=rf, X=X_train, interpreter=interpreter)\n",
    "interpreter.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.7333333333333333, 0.846153846153846]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_fidelity(\n",
    "    X_test,\n",
    "    interpreter,\n",
    "    model=rf,\n",
    "    score_function=[precision_score, recall_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 3.4373 - accuracy: 0.6692\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 2.6298 - accuracy: 0.6466\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.8271\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8538 - accuracy: 0.8271\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8990 - accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8094 - accuracy: 0.8797\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 1.0302 - accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.8946 - accuracy: 0.9023\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.8722\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.3158 - accuracy: 0.8120\n",
      "WARNING:tensorflow:From /Users/ilanmoscovitz/Documents/Metis/Projects/local_lw/wittgenstein_project/wittgenstein/interpret.py:122: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[[Proline=>1227.0] V\n",
      "[Malicacid=1.76-1.9] V\n",
      "[Proline=1048.0-1227.0] V\n",
      "[Proline=880.0-1048.0] V\n",
      "[Proline=736.0-880.0]]\n"
     ]
    }
   ],
   "source": [
    "# Interpret a Tensorflow/Keras model\n",
    "\n",
    "seed(1)\n",
    "wine_df = pd.read_csv(inpath + \"wine.csv\")\n",
    "X_wine, y_wine = wine_df.drop(\"Class\", axis=1), wine_df[\"Class\"]\n",
    "y_wine = y_wine.map(lambda x: True if x==1 else False)\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X, y, random_state=42)\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(60, input_dim=13, activation='relu'))\n",
    "mlp.add(Dense(30, activation='relu'))\n",
    "mlp.add(Dense(1, activation='sigmoid'))\n",
    "mlp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "mlp.fit(\n",
    "    X_train_wine,\n",
    "    y_train_wine,\n",
    "    batch_size=1,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "ruleset, _ = interpret_model(model=mlp, X=X_train, interpreter=interpreter)\n",
    "interpreter.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.85, 0.9444444444444444, 0.8947368421052632]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_fidelity(\n",
    "    X_test,\n",
    "    interpreter,\n",
    "    model=mlp,\n",
    "    score_function=[precision_score, recall_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
